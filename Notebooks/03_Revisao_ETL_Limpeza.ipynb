{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df9e8835",
   "metadata": {},
   "source": [
    "### 3.1. Justificativa Técnica e Abordagem Profissional\n",
    "\n",
    "O pipeline de ETL dos Dados Antigos (2020-2022) foi desenvolvido com foco em **robustez e auditabilidade**, pilares essenciais da Engenharia de Dados.\n",
    "\n",
    "| Desafio | Solução Profissional Implementada | Justificativa |\n",
    "| :--- | :--- | :--- |\n",
    "| **Inconsistência de Encoding** | Tentativa sequencial de `utf-8-sig`, `latin-1`, e `iso-8859-1`. | **Tolerância a Falhas:** Garante a extração de dados de fontes não padronizadas sem intervenção manual. |\n",
    "| **Erros de Tipagem** | Limpeza robusta de caracteres (R$, vírgulas) antes da conversão para `float`. | **Integridade de Dados:** Previne a perda de dados e o erro de cálculo, crucial para métricas financeiras. |\n",
    "| **Nomenclatura Inconsistente** | Uso de um `map_colunas` explícito. | **Manutenibilidade:** O mapeamento é necessário para lidar com **caracteres invisíveis** (Ex: `Descrição CATMAT` com Unicode `\\xa0`) e garantir que a nomenclatura dos dados antigos seja **idêntica** ao formato dos dados novos, facilitando a integração futura no Data Warehouse. |\n",
    "| **Rastreamento de Erros** | Uso de **`logging`** extenso em cada método e `try/except` com `traceback`. | **Auditabilidade:** Permite a identificação precisa do ponto de falha (qual arquivo, qual método) durante o processamento, uma necessidade crítica em ambientes de produção. |\n",
    "| **Inversão de Colunas** | Lógica heurística baseada em contagem de letras/dígitos. | **Defesa contra Inconsistência:** Solução avançada para um problema comum em *datasets* legados, automatizando o que seria um trabalho manual e propenso a erros. |\n",
    "| **Dados Faltantes** | Criação de colunas padrão (`capacidade`, `unidade_medida`) | **Consistência de Schema:** Garante que todos os anos tenham a mesma estrutura para unificação posterior |\n",
    "| **Validação de Domínio** | Verificação de valores válidos em `tipo_compra`, `generico` | **Qualidade Analítica:** Previne análises com categorias inconsistentes |\n",
    "| **Processamento em Lote** | Consolidação de múltiplos anos em uma única execução | **Eficiência Operacional:** Reduz tempo de processamento e complexidade de orchestration |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e147157",
   "metadata": {},
   "source": [
    "### 3.2. Etapas do ETL (Fase de Preparação dos Dados)\n",
    "\n",
    "A fase de **Preparação dos Dados** é a mais complexa no pipeline antigo, sendo orquestrada pelo método `_processar_arquivo`.\n",
    "\n",
    "| Etapa | Método | Justificativa Técnica |\n",
    "| :--- | :--- | :--- |\n",
    "| **1. Padronização** | `_padronizar_colunas` | Uniformiza o nome das colunas para *snake\\_case* e adiciona a coluna `ano_compra` para rastreamento. |\n",
    "| **2. Correção de Estrutura** | `_corrigir_colunas_trocadas` | Realiza a correção heurística das colunas Nome/CNPJ trocadas, garantindo que o dado chegue à coluna correta. |\n",
    "| **3. Tratamento de Tipos** | `_corrigir_tipos` | Aplica a limpeza robusta em campos numéricos (`qtd_itens_comprados`, `preco_unitario`), datas (`compra`, `insercao` com `dayfirst=True`) e padroniza campos categóricos (`generico` para SIM/NÃO, `tipo_compra` para ADMINISTRATIVA/JUDICIAL/INDEFINIDO). |\n",
    "| **4. Preenchimento** | `_adicionar_colunas_vazias` | Insere colunas ausentes (`capacidade`, `unidade_medida`) com valores padrão (`0.0` e `'NA'`) para garantir a compatibilidade com o formato dos Dados Novos (2023+). |\n",
    "| **5. Organização** | `_reordenar_colunas` | Garante que a ordem final das colunas seja idêntica ao *schema* esperado no Data Warehouse. |\n",
    "| **6. Carga (Load)** | `processar_todos_antigos` | Consolida todos os DataFrames limpos (`pd.concat`) e salva o resultado final no formato CSV. |\n",
    "| **7. Validação de Dados** | `_validar_dados_processados` | Verifica integridade referencial, domínios válidos e regras de negócio |\n",
    "| **8. Log de Métricas** | `_gerar_metricas_qualidade` | Produz indicadores de qualidade (completude, consistência) para auditoria |\n",
    "| **9. Documentação de Linhagem** | Metadados de transformação | **Rastreabilidade:** Permite auditoria completa das transformações aplicadas |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d0816e",
   "metadata": {},
   "source": [
    "### 3.3. Benefícios e Implicação para o Projeto de Análise de Compras de Medicamentos\n",
    "\n",
    "O pipeline ETL Antigo atende aos objetivos de Modelagem e Avaliação do CRISP-DM, produzindo um conjunto de dados **confiável e pronto para o consumo**:\n",
    "\n",
    "* **Modelagem Dimensional:** O processo garante que as chaves de ligação (CNPJs, `codigo_br`, `ano_compra`) estejam limpas e no formato **requerido** para a criação de um *Schema Star* (Tabela Fato).\n",
    "* **Integridade de Dados:** O tratamento robusto de valores regionais e a correção de erros estruturais eliminam a necessidade de processamento manual, reduzindo a chance de erros humanos e garantindo a **confiabilidade** dos dados para o Dashboard de Análise de Gestão de Preços (Otimização) e Gestão de Demanda (Controle de Risco)\n",
    "* **Consolidação:** A junção de múltiplos arquivos CSV de forma automatizada permite a **análise de séries temporais** (2020 a 2022) com o mínimo de esforço de manutenção.\n",
    "* **Framework Reutilizável:** Metodologia aplicável a outros datasets de compras públicas.\n",
    "* **Redução de Debt Técnico:** Processo automatizado elimina trabalho manual recorrente.\n",
    "* **Base para Dashboard em Tempo Real:** Pipeline pode ser adaptado para processamento incremental."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc042770",
   "metadata": {},
   "source": [
    "**Alinhamento com CRISP-DM:**\n",
    "- **Business Understanding:** Compras públicas precisam de transparência e controle\n",
    "- **Data Understanding:** Identificação de inconsistências nos dados históricos  \n",
    "- **Data Preparation:** Pipeline ETL robusto (este notebook)\n",
    "- **Modeling:** Pronto para modelagem dimensional e análises (próxima fase)\n",
    "- **Evaluation:** Validação através de relatórios de qualidade\n",
    "- **Deployment:** Processo automatizável para atualizações futuras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d2142b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import logging\n",
    "import re\n",
    "import traceback\n",
    "from IPython.display import display # Importação necessária para o notebook\n",
    "\n",
    "# Configuração de Log (ajustada para melhor visualização no notebook)\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s - %(message)s')\n",
    "\n",
    "class ETLComprasAntigos:\n",
    "    def __init__(self, pasta_base):\n",
    "        self.pasta_base = pasta_base # Usa o caminho passado pelo main.py\n",
    "        self.pasta_raw = os.path.join(self.pasta_base, \"raw\")\n",
    "        self.pasta_processed = os.path.join(self.pasta_base, \"processed\")\n",
    "        \n",
    "        print(f\"ETL Antigos - Usando caminho base: {self.pasta_base}\")\n",
    "        print(f\"Raw: {self.pasta_raw}\")\n",
    "        print(f\"Processed: {self.pasta_processed}\")\n",
    "\n",
    "        # Garante pastas\n",
    "        os.makedirs(self.pasta_raw, exist_ok=True)\n",
    "        os.makedirs(self.pasta_processed, exist_ok=True)\n",
    "        \n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        # Garante que o handler do logger está configurado\n",
    "        if not self.logger.handlers:\n",
    "            handler = logging.StreamHandler()\n",
    "            formatter = logging.Formatter('%(levelname)s - %(message)s')\n",
    "            handler.setFormatter(formatter)\n",
    "            self.logger.addHandler(handler)\n",
    "        self.logger.setLevel(logging.INFO)\n",
    "\n",
    "    # --- MÉTODOS DE TRANSFORMAÇÃO ESPECÍFICOS PARA ANOS ANTIGOS ---\n",
    "    \n",
    "    # Padroniza nomes de colunas de ANOS ANTIGOS para snake_case do NOVO formato.    \n",
    "    def _padronizar_colunas(self, df): \n",
    "        self.logger.info(\"Padronizando nomes de colunas...\")\n",
    "        \n",
    "        # Lista de colunas a serem limpas (removendo espaços e caracteres extras)\n",
    "        df.columns = df.columns.str.strip().str.replace(' ', '_').str.replace('__', '_')\n",
    "\n",
    "        map_colunas = {\n",
    "        'Ano': 'ano_compra',\n",
    "        'Código_BR': 'codigo_br',\n",
    "        'Descrição CATMAT': 'descricao_catmat',\n",
    "        \n",
    "        \n",
    "        # CORREÇÃO 1: Mapear para o nome final desejado 'unidade_fornecimento'\n",
    "        ' Unidade_de_Fornecimento ': 'unidade_fornecimento', \n",
    "        'Unidade_de_Fornecimento': 'unidade_fornecimento',   \n",
    "            'Genérico': 'generico',\n",
    "            'Anvisa': 'anvisa',\n",
    "            'Compra': 'compra',\n",
    "            'Modalidade_da_Compra': 'modalidade_compra',\n",
    "            'Inserção': 'insercao',\n",
    "            'Tipo_Compra': 'tipo_compra',\n",
    "            \n",
    "            # Inversões de CNPJ/Nome serão corrigidas posteriormente\n",
    "            'Fabricante': 'cnpj_fabricante_temp',\n",
    "            'CNPJ_Fabricante': 'fabricante_temp',\n",
    "            'Fornecedor': 'cnpj_fornecedor_temp',\n",
    "            'CNPJ_Fornecedor': 'fornecedor_temp',\n",
    "            'Nome_Instituição': 'cnpj_instituicao_temp',\n",
    "            'CNPJ_Instituição': 'nome_instituicao_temp',\n",
    "            \n",
    "            'Município_Instituição': 'municipio_instituicao',\n",
    "            'UF': 'uf',\n",
    "            'Qtd_Itens_Comprados': 'qtd_itens_comprados',\n",
    "            'Preço_Unitário': 'preco_unitario',\n",
    "            \n",
    "            # Se 'unidade_fornecimento_capacidade' já veio como coluna vazia, não a mapeie.\n",
    "        }\n",
    "        \n",
    "        df.rename(columns=map_colunas, inplace=True)\n",
    "        self.logger.info(\"Colunas padronizadas.\")\n",
    "        return df\n",
    "\n",
    "    # Corrige a inversão de CNPJ e Nome que acontece em alguns anos antigos.\n",
    "    def _corrigir_colunas_trocadas(self, df):\n",
    "        \n",
    "        self.logger.info(\"Corrigindo colunas CNPJ/Nome trocadas...\")\n",
    "        \n",
    "        # Lógica de amostra para determinar se a coluna temp_cnpj realmente é o nome (se tem mais letras)\n",
    "        def is_name(series):\n",
    "            # Conta o número de caracteres alfabéticos na amostra\n",
    "            amostra = series.head(100).astype(str).str.replace(r'\\W', '', regex=True)\n",
    "            letras = amostra.str.count(r'[a-zA-Z]').sum()\n",
    "            digitos = amostra.str.count(r'[0-9]').sum()\n",
    "            return letras > digitos * 0.5 # Se mais da metade são letras, é nome\n",
    "\n",
    "        # Fornecedor\n",
    "        if 'cnpj_fornecedor_temp' in df.columns and 'fornecedor_temp' in df.columns:\n",
    "            if is_name(df['cnpj_fornecedor_temp']):\n",
    "                self.logger.info(\"Inversão de Fornecedor detectada e corrigida.\")\n",
    "                df['fornecedor'] = df['cnpj_fornecedor_temp']\n",
    "                df['cnpj_fornecedor'] = df['fornecedor_temp']\n",
    "            else:\n",
    "                df['fornecedor'] = df['fornecedor_temp']\n",
    "                df['cnpj_fornecedor'] = df['cnpj_fornecedor_temp']\n",
    "            df.drop(columns=['cnpj_fornecedor_temp', 'fornecedor_temp'], inplace=True)\n",
    "        \n",
    "        # Fabricante\n",
    "        if 'cnpj_fabricante_temp' in df.columns and 'fabricante_temp' in df.columns:\n",
    "            if is_name(df['cnpj_fabricante_temp']):\n",
    "                self.logger.info(\"Inversão de Fabricante detectada e corrigida.\")\n",
    "                df['fabricante'] = df['cnpj_fabricante_temp']\n",
    "                df['cnpj_fabricante'] = df['fabricante_temp']\n",
    "            else:\n",
    "                df['fabricante'] = df['fabricante_temp']\n",
    "                df['cnpj_fabricante'] = df['cnpj_fabricante_temp']\n",
    "            df.drop(columns=['cnpj_fabricante_temp', 'fabricante_temp'], inplace=True)\n",
    "            \n",
    "        # Instituição\n",
    "        if 'cnpj_instituicao_temp' in df.columns and 'nome_instituicao_temp' in df.columns:\n",
    "            if is_name(df['cnpj_instituicao_temp']):\n",
    "                self.logger.info(\"Inversão de Instituição detectada e corrigida.\")\n",
    "                df['nome_instituicao'] = df['cnpj_instituicao_temp']\n",
    "                df['cnpj_instituicao'] = df['nome_instituicao_temp']\n",
    "            else:\n",
    "                df['nome_instituicao'] = df['nome_instituicao_temp']\n",
    "                df['cnpj_instituicao'] = df['cnpj_instituicao_temp']\n",
    "            df.drop(columns=['cnpj_instituicao_temp', 'nome_instituicao_temp'], inplace=True)\n",
    "            \n",
    "        self.logger.info(\"Colunas CNPJ/Nome ajustadas.\")\n",
    "        return df\n",
    "\n",
    "    # Corrige tipos de dados com limpeza robusta para ANOS ANTIGOS\n",
    "    def _corrigir_tipos(self, df):        \n",
    "        self.logger.info(\"Corrigindo tipos de dados (Antigos) com limpeza robusta...\")\n",
    "\n",
    "        # 1. CORREÇÃO NUMÉRICA ROBUSTA (Qtd e Preço)\n",
    "        colunas_numericas = ['qtd_itens_comprados', 'preco_unitario']\n",
    "        for coluna in colunas_numericas:\n",
    "            if coluna in df.columns:\n",
    "                try:\n",
    "                    # Passo 1: Limpeza da string para formato regional brasileiro\n",
    "                    # Remove R$, parênteses e espaços.\n",
    "                    df[coluna] = df[coluna].astype(str).str.replace(r'[R$()+\\s]', '', regex=True)\n",
    "                    # Remove separadores de milhares (ponto)\n",
    "                    df[coluna] = df[coluna].str.replace('.', '', regex=False)\n",
    "                    # Troca separador decimal (vírgula) por ponto\n",
    "                    df[coluna] = df[coluna].str.replace(',', '.', regex=False)\n",
    "                    \n",
    "                    # Passo 2: Conversão para numérico. 'errors=coerce' transforma falhas em NaN.\n",
    "                    df[coluna] = pd.to_numeric(df[coluna], errors='coerce')\n",
    "\n",
    "                    # Passo 3: Preenche NaN com 0 para garantir o cálculo e evitar erros.\n",
    "                    df[coluna] = df[coluna].fillna(0)\n",
    "                    self.logger.info(f\"{coluna}: convertido para numérico (Limpeza regional aplicada)\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    self.logger.warning(f\"{coluna}: erro na conversão numérica - {e}\")\n",
    "\n",
    "        # Recálculo de preco_total (necessário após a correção dos componentes)\n",
    "        if 'preco_unitario' in df.columns and 'qtd_itens_comprados' in df.columns:\n",
    "            df['preco_total'] = df['qtd_itens_comprados'] * df['preco_unitario']\n",
    "            self.logger.info(\"preco_total recalculado.\")\n",
    "        else:\n",
    "            self.logger.warning(\"Não foi possível calcular preco_total. Colunas ausentes.\")\n",
    "\n",
    "\n",
    "        # 2. CORREÇÃO DE DATAS\n",
    "        colunas_data = ['compra', 'insercao']\n",
    "        for coluna in colunas_data:\n",
    "            if coluna in df.columns:\n",
    "                # Usa dayfirst=True para garantir o formato DD/MM/AA (DD/MM/YYYY)\n",
    "                df[coluna] = pd.to_datetime(df[coluna], errors='coerce', dayfirst=True)\n",
    "                self.logger.info(f\"{coluna}: convertido para data (dayfirst=True)\")\n",
    "                \n",
    "        \n",
    "        # 3. CORREÇÃO DE TIPO DE COMPRA (Padroniza para ADMINISTRATIVA/JUDICIAL em CAIXA ALTA)\n",
    "        if 'tipo_compra' in df.columns:\n",
    "            df['tipo_compra'] = (\n",
    "                df['tipo_compra']\n",
    "                .astype(str)\n",
    "                .str.strip()\n",
    "                .str.upper() \n",
    "                .replace({\n",
    "                    'A': 'ADMINISTRATIVA',\n",
    "                    'J': 'JUDICIAL',\n",
    "                    'ADMINISTRATIVA': 'ADMINISTRATIVA',\n",
    "                    'JUDICIAL': 'JUDICIAL',\n",
    "                })\n",
    "            )\n",
    "            \n",
    "            # Trata valores nulos ou inesperados\n",
    "            valores_validos = ['ADMINISTRATIVA', 'JUDICIAL']\n",
    "            df['tipo_compra'] = df['tipo_compra'].apply(\n",
    "                lambda x: 'INDEFINIDO' if x not in valores_validos else x\n",
    "            )\n",
    "\n",
    "            self.logger.info(f\"tipo_compra: padronizado (ADMINISTRATIVA/JUDICIAL).\")\n",
    "\n",
    "\n",
    "        # 4. PADRONIZAÇÃO DO CÓDIGO BR (Remoção do prefixo 'BR')\n",
    "        if 'codigo_br' in df.columns:\n",
    "            self.logger.info(\"codigo_br: Removendo prefixo 'BR'...\")\n",
    "            \n",
    "            # 1. Converte para string e remove espaços em branco\n",
    "            df['codigo_br'] = df['codigo_br'].astype(str).str.strip()\n",
    "            \n",
    "            # 2. Usa uma expressão regular ou .str.replace() para remover 'BR' se estiver no início\n",
    "            df['codigo_br'] = (\n",
    "                df['codigo_br']\n",
    "                .str.upper() # Coloca em caixa alta para pegar \"br\" ou \"Br\"\n",
    "                .str.replace(r'^BR0*', '', regex=True) # Remove BR e qualquer zero à esquerda subsequente (se for o caso)\n",
    "            )\n",
    "                        \n",
    "            # Garante que o valor resultante seja um número (em string) sem 'BR' e sem espaços.\n",
    "            def limpar_codigo_br(codigo):\n",
    "                if pd.isna(codigo):\n",
    "                    return None\n",
    "                # Remove 'BR' e qualquer caractere não-numérico\n",
    "                codigo_limpo = re.sub(r'^BR', '', str(codigo).strip().upper()) \n",
    "                # Garante que não haja espaço no final\n",
    "                return codigo_limpo.strip() \n",
    "            \n",
    "            df['codigo_br'] = df['codigo_br'].apply(limpar_codigo_br)\n",
    "\n",
    "            self.logger.info(f\"codigo_br: prefixo 'BR' removido e padronizado.\")\n",
    "\n",
    "        \n",
    "        # 5. CORREÇÃO CNPJ/FLAG/STRING\n",
    "        # CNPJs\n",
    "        colunas_cnpj = ['cnpj_instituicao', 'cnpj_fornecedor', 'cnpj_fabricante']\n",
    "        for coluna in colunas_cnpj:\n",
    "            if coluna in df.columns:\n",
    "                df[coluna] = df[coluna].astype(str).str.replace(r'\\D', '', regex=True).str.zfill(14)\n",
    "                self.logger.info(f\"{coluna}: limpeza e zfill(14)\")\n",
    "\n",
    "        \n",
    "        # 6. Flags (Generico)\n",
    "        if 'generico' in df.columns:\n",
    "            df['generico'] = (\n",
    "                df['generico']\n",
    "                .astype(str)\n",
    "                .str.strip()\n",
    "                .str.upper() # Garante que \"Sim\" e \"sim\" virem \"SIM\"\n",
    "                .replace({'NÃO': 'NÃO', 'NAO': 'NÃO'}) # Garante a acentuação\n",
    "                .fillna('NÃO')\n",
    "            )\n",
    "            # Qualquer valor que ainda seja 'S' ou 'N' de um possível erro anterior será corrigido aqui\n",
    "            df['generico'] = df['generico'].replace({'S': 'SIM', 'N': 'NÃO'})\n",
    "            \n",
    "            # Finalmente, qualquer valor que não seja SIM ou NÃO é forçado para NÃO\n",
    "            df['generico'] = df['generico'].apply(lambda x: 'NÃO' if x not in ['SIM', 'NÃO'] else x)\n",
    "\n",
    "            self.logger.info(f\"generico: padronizado (SIM/NÃO) (Antigos anos).\")\n",
    "\n",
    "        # 7. Colunas de texto (limpeza básica)\n",
    "        colunas_string = ['nome_instituicao', 'municipio_instituicao', 'uf',\n",
    "                          'fornecedor', 'fabricante', 'descricao_catmat',\n",
    "                          'unidade_fornecimento_capacidade', 'modalidade_compra', 'tipo_compra', 'anvisa', 'codigo_br']\n",
    "        for coluna in colunas_string:\n",
    "            if coluna in df.columns:\n",
    "                df[coluna] = df[coluna].astype(str).str.strip().replace('nan', '').replace('None', '')\n",
    "        \n",
    "        # O campo anvisa deve ser tratado como string para evitar perdas de leading zeros.\n",
    "        if 'anvisa' in df.columns:\n",
    "            df['anvisa'] = df['anvisa'].str.replace(r'\\D', '', regex=True)\n",
    "\n",
    "        self.logger.info(\"Tipos corrigidos com sucesso.\")\n",
    "        return df\n",
    "    \n",
    "    # Adiciona colunas que não existem nos anos antigos com valores padrão\n",
    "    def _adicionar_colunas_vazias(self, df):        \n",
    "        self.logger.info(\"Adicionando colunas ausentes (capacidade, unidade_medida)...\")\n",
    "        colunas_novas = {\n",
    "            'capacidade': 0.0,\n",
    "            'unidade_medida': 'NA',\n",
    "        }\n",
    "        for col, default in colunas_novas.items():\n",
    "            if col not in df.columns:\n",
    "                df[col] = default\n",
    "        self.logger.info(\"Colunas ausentes adicionadas.\")\n",
    "        return df\n",
    "\n",
    "    # Garante que a ordem das colunas seja igual ao formato NOVO para consolidação.\n",
    "    def _reordenar_colunas(self, df):        \n",
    "        self.logger.info(\"Reordenando colunas...\")\n",
    "        colunas_finais = [\n",
    "            'ano_compra', 'nome_instituicao', 'cnpj_instituicao', 'municipio_instituicao',\n",
    "            'uf', 'compra', 'insercao', 'codigo_br', 'descricao_catmat',\n",
    "            'unidade_fornecimento_capacidade', 'generico', 'anvisa', 'modalidade_compra',\n",
    "            'tipo_compra', 'capacidade', 'unidade_medida', 'cnpj_fornecedor',\n",
    "            'fornecedor', 'cnpj_fabricante', 'fabricante', 'qtd_itens_comprados',\n",
    "            'preco_unitario', 'preco_total'\n",
    "        ]\n",
    "        \n",
    "        # Filtra apenas as colunas que realmente existem no DataFrame\n",
    "        colunas_presentes = [col for col in colunas_finais if col in df.columns]\n",
    "        \n",
    "        # Adiciona colunas presentes que não foram mapeadas na ordem, no final\n",
    "        for col in df.columns:\n",
    "            if col not in colunas_presentes:\n",
    "                colunas_presentes.append(col)\n",
    "        \n",
    "        df = df[colunas_presentes]\n",
    "        self.logger.info(\"Colunas reordenadas.\")\n",
    "        return df\n",
    "\n",
    "    # Executa a sequência de transformações para um único DataFrame antigo.\n",
    "    def _processar_arquivo(self, df):        \n",
    "        df = self._padronizar_colunas(df)\n",
    "        df = self._corrigir_colunas_trocadas(df)\n",
    "        df = self._corrigir_tipos(df)\n",
    "        df = self._adicionar_colunas_vazias(df)\n",
    "        df = self._reordenar_colunas(df)\n",
    "        return df\n",
    "    \n",
    "    # Lista arquivos antigos com correspondência exata de nome YYYY.csv\n",
    "    # --- MÉTODOS DE I/O E EXECUÇÃO (continuação) ---\n",
    "\n",
    "    def listar_arquivos_antigos(self):\n",
    "        \"\"\"\n",
    "        Lista os arquivos CSV de 2020, 2021 e 2022 dentro da pasta 'raw'.\n",
    "        \"\"\"\n",
    "        self.logger.info(\"Verificando arquivos na pasta RAW...\")\n",
    "        \n",
    "        if not os.path.exists(self.pasta_raw):\n",
    "            # Se a pasta não existe (o que pode acontecer se o __init__ falhar em criá-la)\n",
    "            self.logger.error(f\"Pasta raw não existe: {self.pasta_raw}\")\n",
    "            return []\n",
    "            \n",
    "        todos_arquivos = os.listdir(self.pasta_raw)\n",
    "        arquivos_antigos = []\n",
    "        ANOS_ANTIGOS = ['2020', '2021', '2022']\n",
    "        \n",
    "        for f in todos_arquivos:\n",
    "            nome_base, ext = os.path.splitext(f)\n",
    "            # Verifica se o arquivo é CSV e se o nome base corresponde a um ano antigo\n",
    "            if ext.lower() == '.csv' and nome_base in ANOS_ANTIGOS:\n",
    "                caminho = os.path.join(self.pasta_raw, f)\n",
    "                arquivos_antigos.append(caminho)\n",
    "                self.logger.info(f\"Arquivo antigo encontrado: {f}\")\n",
    "\n",
    "        self.logger.info(f\"Total arquivos antigos a processar: {len(arquivos_antigos)}\")\n",
    "        return arquivos_antigos\n",
    "\n",
    "    # Processa todos os arquivos antigos (2020-2022) em lote, com tratamento de erro individual.\n",
    "    def processar_todos_antigos(self):\n",
    "        self.logger.info(\"Iniciando processamento de todos os anos antigos (2020-2022)...\")\n",
    "        \n",
    "        # Cria a pasta de saída se não existir\n",
    "        os.makedirs(self.pasta_processed, exist_ok=True)\n",
    "        \n",
    "        arquivos = self.listar_arquivos_antigos()\n",
    "        \n",
    "        dfs = [] \n",
    "        anos_processados = []\n",
    "        \n",
    "        for arquivo_path in arquivos:\n",
    "            nome_arquivo = os.path.basename(arquivo_path)\n",
    "            self.logger.info(f\"\\n>>INICIANDO processamento do arquivo: {nome_arquivo}\")\n",
    "\n",
    "            df = None\n",
    "            encoding_tentativas = ['utf-8-sig', 'latin-1', 'iso-8859-1'] # Ordem de preferência\n",
    "\n",
    "            for encoding in encoding_tentativas:\n",
    "                try:\n",
    "                    # Tenta ler com a codificação atual\n",
    "                    df = pd.read_csv(arquivo_path, sep=';', encoding=encoding, low_memory=False)\n",
    "                    self.logger.info(f\"Leitura bem-sucedida com encoding: {encoding}\")\n",
    "                    break # Se leu, sai do loop de tentativas\n",
    "                \n",
    "                except UnicodeDecodeError:\n",
    "                    # Se falhou por causa de codificação, tenta a próxima\n",
    "                    self.logger.warning(f\"Falha na leitura com encoding '{encoding}'. Tentando o próximo...\")\n",
    "                \n",
    "                except pd.errors.EmptyDataError:\n",
    "                    self.logger.error(f\"Erro de Dados: Arquivo vazio ou ilegível: {nome_arquivo}\")\n",
    "                    break # Se o erro não for de codificação, quebra o loop de tentativas\n",
    "                \n",
    "                except Exception as e:\n",
    "                    # Captura qualquer outro erro que não seja de codificação na leitura\n",
    "                    self.logger.error(f\"ERRO GRAVE inesperado na leitura de {nome_arquivo}: {e}\")\n",
    "                    self.logger.error(f\"Detalhes do Erro:\\n{traceback.format_exc()}\")\n",
    "                    break\n",
    "\n",
    "            if df is None or df.empty:\n",
    "                self.logger.error(f\"Processamento ABORTADO para {nome_arquivo}. Não foi possível ler o arquivo com as codificações tentadas.\")\n",
    "                continue \n",
    "                        \n",
    "            try:\n",
    "                # Processamento (Onde ocorrem as correções de tipos, padronização, etc.)\n",
    "                df_processado = self._processar_arquivo(df)\n",
    "                \n",
    "                dfs.append(df_processado)\n",
    "                \n",
    "                # Extrai o ano\n",
    "                ano = os.path.splitext(nome_arquivo)[0]\n",
    "                anos_processados.append(ano)\n",
    "                self.logger.info(f\"FINALIZADO com sucesso: {nome_arquivo} ({len(df_processado):,} registros)\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                # Captura erros que ocorrem *após* a leitura (ex: conversão de tipos, limpeza)\n",
    "                self.logger.error(f\"ERRO GRAVE na transformação de {nome_arquivo}. O arquivo será pulado.\")\n",
    "                self.logger.error(f\"Mensagem do Erro: {e}\")\n",
    "                self.logger.error(f\"Detalhes (Traceback):\\n{traceback.format_exc()}\")\n",
    "\n",
    "            # ... [O restante do loop de leitura e processamento] ...\n",
    "\n",
    "        # --- Bloco de Carga (LOAD) e Conclusão \n",
    "        if not dfs: \n",
    "            self.logger.warning(\"\\nNenhum DataFrame foi processado com sucesso para consolidar.\")\n",
    "            return None\n",
    "\n",
    "        self.logger.info(\"\\nTentando consolidar todos os DataFrames processados...\")\n",
    "\n",
    "        df_consolidado = pd.concat(dfs, ignore_index=True)\n",
    "        \n",
    "     # Salvamento\n",
    "        anos_str = \"_\".join(sorted(set(anos_processados)))\n",
    "        caminho_consolidado = os.path.join(self.pasta_processed, f\"compras_antigos_consolidado_{anos_str}.csv\")\n",
    "        # df_consolidado.to_csv(caminho_consolidado, index=False, encoding='utf-8-sig', sep=';')\n",
    "        \n",
    "        self.logger.info(f\"Consolidação completa!\")\n",
    "        self.logger.info(f\"Total de registros: {len(df_consolidado):,}\")\n",
    "        self.logger.info(f\"Anos: {', '.join(sorted(set(anos_processados))) if anos_processados else 'N/A'}\")\n",
    "        self.logger.info(f\"Arquivo: {caminho_consolidado}\")    # ... [Restante do código para logs e return] ...\n",
    "        \n",
    "        return df_consolidado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d47ca53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Iniciando processamento de todos os anos antigos (2020-2022)...\n",
      "INFO - Iniciando processamento de todos os anos antigos (2020-2022)...\n",
      "INFO - Verificando arquivos na pasta RAW...\n",
      "INFO - Verificando arquivos na pasta RAW...\n",
      "INFO - Arquivo antigo encontrado: 2020.csv\n",
      "INFO - Arquivo antigo encontrado: 2020.csv\n",
      "INFO - Arquivo antigo encontrado: 2021.csv\n",
      "INFO - Arquivo antigo encontrado: 2021.csv\n",
      "INFO - Arquivo antigo encontrado: 2022.csv\n",
      "INFO - Arquivo antigo encontrado: 2022.csv\n",
      "INFO - Total arquivos antigos a processar: 3\n",
      "INFO - Total arquivos antigos a processar: 3\n",
      "INFO - \n",
      ">>INICIANDO processamento do arquivo: 2020.csv\n",
      "INFO - \n",
      ">>INICIANDO processamento do arquivo: 2020.csv\n",
      "WARNING - Falha na leitura com encoding 'utf-8-sig'. Tentando o próximo...\n",
      "WARNING - Falha na leitura com encoding 'utf-8-sig'. Tentando o próximo...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ETL - COMPRAS PÚBLICAS ANOS ANTIGOS (2020-2022)\n",
      "============================================================\n",
      "ETL Antigos - Usando caminho base: ../data\n",
      "Raw: ../data\\raw\n",
      "Processed: ../data\\processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Leitura bem-sucedida com encoding: latin-1\n",
      "INFO - Leitura bem-sucedida com encoding: latin-1\n",
      "INFO - Padronizando nomes de colunas...\n",
      "INFO - Padronizando nomes de colunas...\n",
      "INFO - Colunas padronizadas.\n",
      "INFO - Colunas padronizadas.\n",
      "INFO - Corrigindo colunas CNPJ/Nome trocadas...\n",
      "INFO - Corrigindo colunas CNPJ/Nome trocadas...\n",
      "INFO - Colunas CNPJ/Nome ajustadas.\n",
      "INFO - Colunas CNPJ/Nome ajustadas.\n",
      "INFO - Corrigindo tipos de dados (Antigos) com limpeza robusta...\n",
      "INFO - Corrigindo tipos de dados (Antigos) com limpeza robusta...\n",
      "INFO - qtd_itens_comprados: convertido para numérico (Limpeza regional aplicada)\n",
      "INFO - qtd_itens_comprados: convertido para numérico (Limpeza regional aplicada)\n",
      "INFO - preco_unitario: convertido para numérico (Limpeza regional aplicada)\n",
      "INFO - preco_unitario: convertido para numérico (Limpeza regional aplicada)\n",
      "INFO - preco_total recalculado.\n",
      "INFO - preco_total recalculado.\n",
      "C:\\Users\\debor\\AppData\\Local\\Temp\\ipykernel_7396\\551784189.py:168: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[coluna] = pd.to_datetime(df[coluna], errors='coerce', dayfirst=True)\n",
      "INFO - compra: convertido para data (dayfirst=True)\n",
      "INFO - compra: convertido para data (dayfirst=True)\n",
      "C:\\Users\\debor\\AppData\\Local\\Temp\\ipykernel_7396\\551784189.py:168: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[coluna] = pd.to_datetime(df[coluna], errors='coerce', dayfirst=True)\n",
      "INFO - insercao: convertido para data (dayfirst=True)\n",
      "INFO - insercao: convertido para data (dayfirst=True)\n",
      "INFO - tipo_compra: padronizado (ADMINISTRATIVA/JUDICIAL).\n",
      "INFO - tipo_compra: padronizado (ADMINISTRATIVA/JUDICIAL).\n",
      "INFO - codigo_br: Removendo prefixo 'BR'...\n",
      "INFO - codigo_br: Removendo prefixo 'BR'...\n",
      "INFO - codigo_br: prefixo 'BR' removido e padronizado.\n",
      "INFO - codigo_br: prefixo 'BR' removido e padronizado.\n",
      "INFO - cnpj_instituicao: limpeza e zfill(14)\n",
      "INFO - cnpj_instituicao: limpeza e zfill(14)\n",
      "INFO - cnpj_fornecedor: limpeza e zfill(14)\n",
      "INFO - cnpj_fornecedor: limpeza e zfill(14)\n",
      "INFO - cnpj_fabricante: limpeza e zfill(14)\n",
      "INFO - cnpj_fabricante: limpeza e zfill(14)\n",
      "INFO - generico: padronizado (SIM/NÃO) (Antigos anos).\n",
      "INFO - generico: padronizado (SIM/NÃO) (Antigos anos).\n",
      "INFO - Tipos corrigidos com sucesso.\n",
      "INFO - Tipos corrigidos com sucesso.\n",
      "INFO - Adicionando colunas ausentes (capacidade, unidade_medida)...\n",
      "INFO - Adicionando colunas ausentes (capacidade, unidade_medida)...\n",
      "INFO - Colunas ausentes adicionadas.\n",
      "INFO - Colunas ausentes adicionadas.\n",
      "INFO - Reordenando colunas...\n",
      "INFO - Reordenando colunas...\n",
      "INFO - Colunas reordenadas.\n",
      "INFO - Colunas reordenadas.\n",
      "INFO - FINALIZADO com sucesso: 2020.csv (71,227 registros)\n",
      "INFO - FINALIZADO com sucesso: 2020.csv (71,227 registros)\n",
      "INFO - \n",
      ">>INICIANDO processamento do arquivo: 2021.csv\n",
      "INFO - \n",
      ">>INICIANDO processamento do arquivo: 2021.csv\n",
      "WARNING - Falha na leitura com encoding 'utf-8-sig'. Tentando o próximo...\n",
      "WARNING - Falha na leitura com encoding 'utf-8-sig'. Tentando o próximo...\n",
      "INFO - Leitura bem-sucedida com encoding: latin-1\n",
      "INFO - Leitura bem-sucedida com encoding: latin-1\n",
      "INFO - Padronizando nomes de colunas...\n",
      "INFO - Padronizando nomes de colunas...\n",
      "INFO - Colunas padronizadas.\n",
      "INFO - Colunas padronizadas.\n",
      "INFO - Corrigindo colunas CNPJ/Nome trocadas...\n",
      "INFO - Corrigindo colunas CNPJ/Nome trocadas...\n",
      "INFO - Inversão de Fornecedor detectada e corrigida.\n",
      "INFO - Inversão de Fornecedor detectada e corrigida.\n",
      "INFO - Inversão de Fabricante detectada e corrigida.\n",
      "INFO - Inversão de Fabricante detectada e corrigida.\n",
      "INFO - Inversão de Instituição detectada e corrigida.\n",
      "INFO - Inversão de Instituição detectada e corrigida.\n",
      "INFO - Colunas CNPJ/Nome ajustadas.\n",
      "INFO - Colunas CNPJ/Nome ajustadas.\n",
      "INFO - Corrigindo tipos de dados (Antigos) com limpeza robusta...\n",
      "INFO - Corrigindo tipos de dados (Antigos) com limpeza robusta...\n",
      "INFO - qtd_itens_comprados: convertido para numérico (Limpeza regional aplicada)\n",
      "INFO - qtd_itens_comprados: convertido para numérico (Limpeza regional aplicada)\n",
      "INFO - preco_unitario: convertido para numérico (Limpeza regional aplicada)\n",
      "INFO - preco_unitario: convertido para numérico (Limpeza regional aplicada)\n",
      "INFO - preco_total recalculado.\n",
      "INFO - preco_total recalculado.\n",
      "INFO - compra: convertido para data (dayfirst=True)\n",
      "INFO - compra: convertido para data (dayfirst=True)\n",
      "INFO - insercao: convertido para data (dayfirst=True)\n",
      "INFO - insercao: convertido para data (dayfirst=True)\n",
      "INFO - tipo_compra: padronizado (ADMINISTRATIVA/JUDICIAL).\n",
      "INFO - tipo_compra: padronizado (ADMINISTRATIVA/JUDICIAL).\n",
      "INFO - codigo_br: Removendo prefixo 'BR'...\n",
      "INFO - codigo_br: Removendo prefixo 'BR'...\n",
      "INFO - codigo_br: prefixo 'BR' removido e padronizado.\n",
      "INFO - codigo_br: prefixo 'BR' removido e padronizado.\n",
      "INFO - cnpj_instituicao: limpeza e zfill(14)\n",
      "INFO - cnpj_instituicao: limpeza e zfill(14)\n",
      "INFO - cnpj_fornecedor: limpeza e zfill(14)\n",
      "INFO - cnpj_fornecedor: limpeza e zfill(14)\n",
      "INFO - cnpj_fabricante: limpeza e zfill(14)\n",
      "INFO - cnpj_fabricante: limpeza e zfill(14)\n",
      "INFO - generico: padronizado (SIM/NÃO) (Antigos anos).\n",
      "INFO - generico: padronizado (SIM/NÃO) (Antigos anos).\n",
      "INFO - Tipos corrigidos com sucesso.\n",
      "INFO - Tipos corrigidos com sucesso.\n",
      "INFO - Adicionando colunas ausentes (capacidade, unidade_medida)...\n",
      "INFO - Adicionando colunas ausentes (capacidade, unidade_medida)...\n",
      "INFO - Colunas ausentes adicionadas.\n",
      "INFO - Colunas ausentes adicionadas.\n",
      "INFO - Reordenando colunas...\n",
      "INFO - Reordenando colunas...\n",
      "INFO - Colunas reordenadas.\n",
      "INFO - Colunas reordenadas.\n",
      "INFO - FINALIZADO com sucesso: 2021.csv (70,893 registros)\n",
      "INFO - FINALIZADO com sucesso: 2021.csv (70,893 registros)\n",
      "INFO - \n",
      ">>INICIANDO processamento do arquivo: 2022.csv\n",
      "INFO - \n",
      ">>INICIANDO processamento do arquivo: 2022.csv\n",
      "WARNING - Falha na leitura com encoding 'utf-8-sig'. Tentando o próximo...\n",
      "WARNING - Falha na leitura com encoding 'utf-8-sig'. Tentando o próximo...\n",
      "INFO - Leitura bem-sucedida com encoding: latin-1\n",
      "INFO - Leitura bem-sucedida com encoding: latin-1\n",
      "INFO - Padronizando nomes de colunas...\n",
      "INFO - Padronizando nomes de colunas...\n",
      "INFO - Colunas padronizadas.\n",
      "INFO - Colunas padronizadas.\n",
      "INFO - Corrigindo colunas CNPJ/Nome trocadas...\n",
      "INFO - Corrigindo colunas CNPJ/Nome trocadas...\n",
      "INFO - Inversão de Fornecedor detectada e corrigida.\n",
      "INFO - Inversão de Fornecedor detectada e corrigida.\n",
      "INFO - Inversão de Fabricante detectada e corrigida.\n",
      "INFO - Inversão de Fabricante detectada e corrigida.\n",
      "INFO - Inversão de Instituição detectada e corrigida.\n",
      "INFO - Inversão de Instituição detectada e corrigida.\n",
      "INFO - Colunas CNPJ/Nome ajustadas.\n",
      "INFO - Colunas CNPJ/Nome ajustadas.\n",
      "INFO - Corrigindo tipos de dados (Antigos) com limpeza robusta...\n",
      "INFO - Corrigindo tipos de dados (Antigos) com limpeza robusta...\n",
      "INFO - qtd_itens_comprados: convertido para numérico (Limpeza regional aplicada)\n",
      "INFO - qtd_itens_comprados: convertido para numérico (Limpeza regional aplicada)\n",
      "INFO - preco_unitario: convertido para numérico (Limpeza regional aplicada)\n",
      "INFO - preco_unitario: convertido para numérico (Limpeza regional aplicada)\n",
      "INFO - preco_total recalculado.\n",
      "INFO - preco_total recalculado.\n",
      "C:\\Users\\debor\\AppData\\Local\\Temp\\ipykernel_7396\\551784189.py:168: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[coluna] = pd.to_datetime(df[coluna], errors='coerce', dayfirst=True)\n",
      "INFO - compra: convertido para data (dayfirst=True)\n",
      "INFO - compra: convertido para data (dayfirst=True)\n",
      "C:\\Users\\debor\\AppData\\Local\\Temp\\ipykernel_7396\\551784189.py:168: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[coluna] = pd.to_datetime(df[coluna], errors='coerce', dayfirst=True)\n",
      "INFO - insercao: convertido para data (dayfirst=True)\n",
      "INFO - insercao: convertido para data (dayfirst=True)\n",
      "INFO - tipo_compra: padronizado (ADMINISTRATIVA/JUDICIAL).\n",
      "INFO - tipo_compra: padronizado (ADMINISTRATIVA/JUDICIAL).\n",
      "INFO - codigo_br: Removendo prefixo 'BR'...\n",
      "INFO - codigo_br: Removendo prefixo 'BR'...\n",
      "INFO - codigo_br: prefixo 'BR' removido e padronizado.\n",
      "INFO - codigo_br: prefixo 'BR' removido e padronizado.\n",
      "INFO - cnpj_instituicao: limpeza e zfill(14)\n",
      "INFO - cnpj_instituicao: limpeza e zfill(14)\n",
      "INFO - cnpj_fornecedor: limpeza e zfill(14)\n",
      "INFO - cnpj_fornecedor: limpeza e zfill(14)\n",
      "INFO - cnpj_fabricante: limpeza e zfill(14)\n",
      "INFO - cnpj_fabricante: limpeza e zfill(14)\n",
      "INFO - generico: padronizado (SIM/NÃO) (Antigos anos).\n",
      "INFO - generico: padronizado (SIM/NÃO) (Antigos anos).\n",
      "INFO - Tipos corrigidos com sucesso.\n",
      "INFO - Tipos corrigidos com sucesso.\n",
      "INFO - Adicionando colunas ausentes (capacidade, unidade_medida)...\n",
      "INFO - Adicionando colunas ausentes (capacidade, unidade_medida)...\n",
      "INFO - Colunas ausentes adicionadas.\n",
      "INFO - Colunas ausentes adicionadas.\n",
      "INFO - Reordenando colunas...\n",
      "INFO - Reordenando colunas...\n",
      "INFO - Colunas reordenadas.\n",
      "INFO - Colunas reordenadas.\n",
      "INFO - FINALIZADO com sucesso: 2022.csv (69,028 registros)\n",
      "INFO - FINALIZADO com sucesso: 2022.csv (69,028 registros)\n",
      "INFO - \n",
      "Tentando consolidar todos os DataFrames processados...\n",
      "INFO - \n",
      "Tentando consolidar todos os DataFrames processados...\n",
      "INFO - Consolidação completa!\n",
      "INFO - Consolidação completa!\n",
      "INFO - Total de registros: 211,148\n",
      "INFO - Total de registros: 211,148\n",
      "INFO - Anos: 2020, 2021, 2022\n",
      "INFO - Anos: 2020, 2021, 2022\n",
      "INFO - Arquivo: ../data\\processed\\compras_antigos_consolidado_2020_2021_2022.csv\n",
      "INFO - Arquivo: ../data\\processed\\compras_antigos_consolidado_2020_2021_2022.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROCESSAMENTO DE ANOS ANTIGOS CONCLUÍDO! 211,148 registros consolidados.\n",
      "\n",
      "--- Amostra do DataFrame Consolidado (Saída Final do ETL) ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ano_compra",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "nome_instituicao",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "cnpj_instituicao",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "municipio_instituicao",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "uf",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "compra",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "insercao",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "codigo_br",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "descricao_catmat",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "generico",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "anvisa",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "modalidade_compra",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "tipo_compra",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "capacidade",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "unidade_medida",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "cnpj_fornecedor",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "fornecedor",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "cnpj_fabricante",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "fabricante",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "qtd_itens_comprados",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "preco_unitario",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "preco_total",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "unidade_fornecimento",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "fb62456f-42b6-44bf-9986-418da262a95f",
       "rows": [
        [
         "0",
         "2020",
         "FUNDO MUNICIPAL DE SAUDE",
         "09102679000102",
         "FERREIROS",
         "PE",
         "2020-11-20 00:00:00",
         "2020-12-16 00:00:00",
         "233632",
         "PETROLATO, ASPECTO FÍSICO:LÍQUIDO, TIPO:LAXATIVO, USO:ORAL",
         "NÃO",
         "1004307440077",
         "Pregão",
         "ADMINISTRATIVA",
         "0.0",
         "NA",
         "23680034000170",
         "D.ARAUJO COMERCIAL EIRELI",
         "61190096000192",
         "EUROFARMA LABORATORIOS LTDA",
         "60",
         "3.78",
         "226.79999999999998",
         "FRASCO 100,00 ML   "
        ],
        [
         "1",
         "2020",
         "MUNICIPIO DE UBATUBA",
         "46482857000196",
         "UBATUBA",
         "SP",
         "2020-01-03 00:00:00",
         "2020-03-31 00:00:00",
         "233632",
         "PETROLATO, ASPECTO FÍSICO:LÍQUIDO, TIPO:LAXATIVO, USO:ORAL",
         "NÃO",
         "",
         "Pregão",
         "ADMINISTRATIVA",
         "0.0",
         "NA",
         "67729178000491",
         "COMERCIAL CIRURGICA RIOCLARENSE LTDA",
         "08055634000153",
         "IMEC-INDUSTRIA DE MEDICAMENTOS CUSTODIA LTDA - EPP",
         "4500",
         "1.77",
         "7965.0",
         "FRASCO 100,00 ML   "
        ],
        [
         "2",
         "2020",
         "FUNDO MUNICIPAL DE SAUDE DE ALIANCA",
         "10759784000190",
         "ALIANCA",
         "PE",
         "2020-01-06 00:00:00",
         "2020-03-05 00:00:00",
         "233632",
         "PETROLATO, ASPECTO FÍSICO:LÍQUIDO, TIPO:LAXATIVO, USO:ORAL",
         "NÃO",
         "",
         "Pregão",
         "ADMINISTRATIVA",
         "0.0",
         "NA",
         "23232280000169",
         "ZUCK PAPEIS LTDA",
         "06628333000146",
         "FARMACE - INDUSTRIA QUIMICO-FARMACEUTICA CEARENSE LTDA",
         "210",
         "2.31",
         "485.1",
         "FRASCO 100,00 ML   "
        ],
        [
         "3",
         "2020",
         "FUNDO MUNICIPAL DE SAUDE DE CASCAVEL",
         "09051532000122",
         "CASCAVEL",
         "PR",
         "2020-01-25 00:00:00",
         "2020-02-21 00:00:00",
         "233632",
         "PETROLATO, ASPECTO FÍSICO:LÍQUIDO, TIPO:LAXATIVO, USO:ORAL",
         "NÃO",
         "",
         "Pregão",
         "ADMINISTRATIVA",
         "0.0",
         "NA",
         "00874929000140",
         "MED CENTER COMERCIAL LTDA",
         "06628333000146",
         "FARMACE - INDUSTRIA QUIMICO-FARMACEUTICA CEARENSE LTDA",
         "2000",
         "1.875",
         "3750.0",
         "FRASCO 100,00 ML   "
        ],
        [
         "4",
         "2020",
         "FUNDO MUNICIPAL DE SAUDE",
         "12306005000126",
         "ITATUBA",
         "PB",
         "2020-01-29 00:00:00",
         "2020-10-06 00:00:00",
         "233632",
         "PETROLATO, ASPECTO FÍSICO:LÍQUIDO, TIPO:LAXATIVO, USO:ORAL",
         "NÃO",
         "",
         "Pregão",
         "ADMINISTRATIVA",
         "0.0",
         "NA",
         "08674752000140",
         "CIRURGICA MONTEBELLO LTDA",
         "08055634000153",
         "IMEC-INDUSTRIA DE MEDICAMENTOS CUSTODIA LTDA - EPP",
         "240",
         "2.13",
         "511.2",
         "FRASCO 100,00 ML   "
        ]
       ],
       "shape": {
        "columns": 23,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ano_compra</th>\n",
       "      <th>nome_instituicao</th>\n",
       "      <th>cnpj_instituicao</th>\n",
       "      <th>municipio_instituicao</th>\n",
       "      <th>uf</th>\n",
       "      <th>compra</th>\n",
       "      <th>insercao</th>\n",
       "      <th>codigo_br</th>\n",
       "      <th>descricao_catmat</th>\n",
       "      <th>generico</th>\n",
       "      <th>...</th>\n",
       "      <th>capacidade</th>\n",
       "      <th>unidade_medida</th>\n",
       "      <th>cnpj_fornecedor</th>\n",
       "      <th>fornecedor</th>\n",
       "      <th>cnpj_fabricante</th>\n",
       "      <th>fabricante</th>\n",
       "      <th>qtd_itens_comprados</th>\n",
       "      <th>preco_unitario</th>\n",
       "      <th>preco_total</th>\n",
       "      <th>unidade_fornecimento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>FUNDO MUNICIPAL DE SAUDE</td>\n",
       "      <td>09102679000102</td>\n",
       "      <td>FERREIROS</td>\n",
       "      <td>PE</td>\n",
       "      <td>2020-11-20</td>\n",
       "      <td>2020-12-16</td>\n",
       "      <td>233632</td>\n",
       "      <td>PETROLATO, ASPECTO FÍSICO:LÍQUIDO, TIPO:LAXATI...</td>\n",
       "      <td>NÃO</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>23680034000170</td>\n",
       "      <td>D.ARAUJO COMERCIAL EIRELI</td>\n",
       "      <td>61190096000192</td>\n",
       "      <td>EUROFARMA LABORATORIOS LTDA</td>\n",
       "      <td>60</td>\n",
       "      <td>3.780</td>\n",
       "      <td>226.8</td>\n",
       "      <td>FRASCO 100,00 ML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>MUNICIPIO DE UBATUBA</td>\n",
       "      <td>46482857000196</td>\n",
       "      <td>UBATUBA</td>\n",
       "      <td>SP</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>233632</td>\n",
       "      <td>PETROLATO, ASPECTO FÍSICO:LÍQUIDO, TIPO:LAXATI...</td>\n",
       "      <td>NÃO</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>67729178000491</td>\n",
       "      <td>COMERCIAL CIRURGICA RIOCLARENSE LTDA</td>\n",
       "      <td>08055634000153</td>\n",
       "      <td>IMEC-INDUSTRIA DE MEDICAMENTOS CUSTODIA LTDA -...</td>\n",
       "      <td>4500</td>\n",
       "      <td>1.770</td>\n",
       "      <td>7965.0</td>\n",
       "      <td>FRASCO 100,00 ML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>FUNDO MUNICIPAL DE SAUDE DE ALIANCA</td>\n",
       "      <td>10759784000190</td>\n",
       "      <td>ALIANCA</td>\n",
       "      <td>PE</td>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>2020-03-05</td>\n",
       "      <td>233632</td>\n",
       "      <td>PETROLATO, ASPECTO FÍSICO:LÍQUIDO, TIPO:LAXATI...</td>\n",
       "      <td>NÃO</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>23232280000169</td>\n",
       "      <td>ZUCK PAPEIS LTDA</td>\n",
       "      <td>06628333000146</td>\n",
       "      <td>FARMACE - INDUSTRIA QUIMICO-FARMACEUTICA CEARE...</td>\n",
       "      <td>210</td>\n",
       "      <td>2.310</td>\n",
       "      <td>485.1</td>\n",
       "      <td>FRASCO 100,00 ML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>FUNDO MUNICIPAL DE SAUDE DE CASCAVEL</td>\n",
       "      <td>09051532000122</td>\n",
       "      <td>CASCAVEL</td>\n",
       "      <td>PR</td>\n",
       "      <td>2020-01-25</td>\n",
       "      <td>2020-02-21</td>\n",
       "      <td>233632</td>\n",
       "      <td>PETROLATO, ASPECTO FÍSICO:LÍQUIDO, TIPO:LAXATI...</td>\n",
       "      <td>NÃO</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>00874929000140</td>\n",
       "      <td>MED CENTER COMERCIAL LTDA</td>\n",
       "      <td>06628333000146</td>\n",
       "      <td>FARMACE - INDUSTRIA QUIMICO-FARMACEUTICA CEARE...</td>\n",
       "      <td>2000</td>\n",
       "      <td>1.875</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>FRASCO 100,00 ML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>FUNDO MUNICIPAL DE SAUDE</td>\n",
       "      <td>12306005000126</td>\n",
       "      <td>ITATUBA</td>\n",
       "      <td>PB</td>\n",
       "      <td>2020-01-29</td>\n",
       "      <td>2020-10-06</td>\n",
       "      <td>233632</td>\n",
       "      <td>PETROLATO, ASPECTO FÍSICO:LÍQUIDO, TIPO:LAXATI...</td>\n",
       "      <td>NÃO</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>08674752000140</td>\n",
       "      <td>CIRURGICA MONTEBELLO LTDA</td>\n",
       "      <td>08055634000153</td>\n",
       "      <td>IMEC-INDUSTRIA DE MEDICAMENTOS CUSTODIA LTDA -...</td>\n",
       "      <td>240</td>\n",
       "      <td>2.130</td>\n",
       "      <td>511.2</td>\n",
       "      <td>FRASCO 100,00 ML</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ano_compra                      nome_instituicao cnpj_instituicao  \\\n",
       "0        2020              FUNDO MUNICIPAL DE SAUDE   09102679000102   \n",
       "1        2020                  MUNICIPIO DE UBATUBA   46482857000196   \n",
       "2        2020   FUNDO MUNICIPAL DE SAUDE DE ALIANCA   10759784000190   \n",
       "3        2020  FUNDO MUNICIPAL DE SAUDE DE CASCAVEL   09051532000122   \n",
       "4        2020              FUNDO MUNICIPAL DE SAUDE   12306005000126   \n",
       "\n",
       "  municipio_instituicao  uf     compra   insercao codigo_br  \\\n",
       "0             FERREIROS  PE 2020-11-20 2020-12-16    233632   \n",
       "1               UBATUBA  SP 2020-01-03 2020-03-31    233632   \n",
       "2               ALIANCA  PE 2020-01-06 2020-03-05    233632   \n",
       "3              CASCAVEL  PR 2020-01-25 2020-02-21    233632   \n",
       "4               ITATUBA  PB 2020-01-29 2020-10-06    233632   \n",
       "\n",
       "                                    descricao_catmat generico  ... capacidade  \\\n",
       "0  PETROLATO, ASPECTO FÍSICO:LÍQUIDO, TIPO:LAXATI...      NÃO  ...        0.0   \n",
       "1  PETROLATO, ASPECTO FÍSICO:LÍQUIDO, TIPO:LAXATI...      NÃO  ...        0.0   \n",
       "2  PETROLATO, ASPECTO FÍSICO:LÍQUIDO, TIPO:LAXATI...      NÃO  ...        0.0   \n",
       "3  PETROLATO, ASPECTO FÍSICO:LÍQUIDO, TIPO:LAXATI...      NÃO  ...        0.0   \n",
       "4  PETROLATO, ASPECTO FÍSICO:LÍQUIDO, TIPO:LAXATI...      NÃO  ...        0.0   \n",
       "\n",
       "  unidade_medida cnpj_fornecedor                            fornecedor  \\\n",
       "0             NA  23680034000170             D.ARAUJO COMERCIAL EIRELI   \n",
       "1             NA  67729178000491  COMERCIAL CIRURGICA RIOCLARENSE LTDA   \n",
       "2             NA  23232280000169                      ZUCK PAPEIS LTDA   \n",
       "3             NA  00874929000140             MED CENTER COMERCIAL LTDA   \n",
       "4             NA  08674752000140             CIRURGICA MONTEBELLO LTDA   \n",
       "\n",
       "  cnpj_fabricante                                         fabricante  \\\n",
       "0  61190096000192                        EUROFARMA LABORATORIOS LTDA   \n",
       "1  08055634000153  IMEC-INDUSTRIA DE MEDICAMENTOS CUSTODIA LTDA -...   \n",
       "2  06628333000146  FARMACE - INDUSTRIA QUIMICO-FARMACEUTICA CEARE...   \n",
       "3  06628333000146  FARMACE - INDUSTRIA QUIMICO-FARMACEUTICA CEARE...   \n",
       "4  08055634000153  IMEC-INDUSTRIA DE MEDICAMENTOS CUSTODIA LTDA -...   \n",
       "\n",
       "  qtd_itens_comprados preco_unitario preco_total  unidade_fornecimento  \n",
       "0                  60          3.780       226.8   FRASCO 100,00 ML     \n",
       "1                4500          1.770      7965.0   FRASCO 100,00 ML     \n",
       "2                 210          2.310       485.1   FRASCO 100,00 ML     \n",
       "3                2000          1.875      3750.0   FRASCO 100,00 ML     \n",
       "4                 240          2.130       511.2   FRASCO 100,00 ML     \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Função de conveniência\n",
    "def processar_anos_antigos():    \n",
    "    \n",
    "    etl_antigo = ETLComprasAntigos(\"../data\") \n",
    "    return etl_antigo.processar_todos_antigos()\n",
    "\n",
    "# Bloco de execução para o notebook\n",
    "print(\"=\" * 60)\n",
    "print(\"ETL - COMPRAS PÚBLICAS ANOS ANTIGOS (2020-2022)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "df_antigos = None\n",
    "\n",
    "try:\n",
    "    df_antigos = processar_anos_antigos()\n",
    "    \n",
    "    if df_antigos is not None:\n",
    "        print(f\"\\nPROCESSAMENTO DE ANOS ANTIGOS CONCLUÍDO! {len(df_antigos):,} registros consolidados.\")\n",
    "    else:\n",
    "        print(\"\\nO pipeline foi concluído, mas nenhum dado pôde ser consolidado.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"\\nERRO FATAL NA EXECUÇÃO: {e}\")\n",
    "    print(f\"Detalhes: {traceback.format_exc()}\")\n",
    "\n",
    "# EXIBIÇÃO DA SAÍDA FINAL (Requisito de documentação do notebook)\n",
    "if df_antigos is not None:\n",
    "    print(\"\\n--- Amostra do DataFrame Consolidado (Saída Final do ETL) ---\")\n",
    "    display(df_antigos.head())\n",
    "    \n",
    "def _gerar_relatorio_qualidade(df):\n",
    "    metricas = {\n",
    "        'registros_processados': len(df),\n",
    "        'completude_cnpj': (df['cnpj_instituicao'] != '').mean(),\n",
    "        'valores_numericos_validos': df[['qtd_itens_comprados', 'preco_unitario']].notna().mean(),\n",
    "        'anos_cobertos': df['ano_compra'].nunique()\n",
    "    }\n",
    "    return metricas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
